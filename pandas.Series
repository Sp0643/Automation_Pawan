Hereâ€™s a complete Python markdown version you can copy-paste directly into your Jupyter notebook to teach or reference all basic pandas.Series functions.


---

# ğŸ“˜ Basic Functions in pandas.Series

## ğŸ“Š Structure & Type

```python
import pandas as pd

s = pd.Series([10, 20, 30, 40, 50], index=['a', 'b', 'c', 'd', 'e'])

type(s)          # Check type
len(s)           # Number of elements
s.shape          # Shape of the series
s.dtype          # Data type of the values
s.index          # Index labels
s.values         # Underlying numpy array


---

ğŸ” Data Inspection

s.head()         # First 5 elements
s.tail()         # Last 5 elements
s.sample(2)      # Random 2 elements
s.unique()       # Unique values
s.nunique()      # Number of unique values
s.value_counts() # Frequency count of values


---

ğŸ“ˆ Statistical Summary

s.sum()          # Sum of values
s.mean()         # Mean (average)
s.median()       # Median value
s.mode()         # Most frequent value(s)
s.std()          # Standard deviation
s.min()          # Minimum value
s.max()          # Maximum value
s.describe()     # Statistical summary


---

ğŸ”¤ Sorting & Indexing

s.sort_values()        # Sort by values
s.sort_index()         # Sort by index
s.reindex(['c', 'a', 'e', 'b', 'd'])  # Change order of index
s.reset_index()        # Reset index (returns DataFrame)


---

ğŸ“Œ Accessing Values

s['a']                 # Access by label
s[0]                   # Access by position
s.loc['b']             # Access by label using .loc
s.iloc[2]              # Access by position using .iloc


---

ğŸ”§ Data Transformation

s.apply(lambda x: x * 2)           # Apply a function
s.map({10: 100, 20: 200})          # Map using dictionary
s.replace(30, 300)                 # Replace value
s.astype(float)                    # Change data type


---

ğŸ§µ String Operations (only for string Series)

s_str = pd.Series(["apple", "banana", "cherry"])

s_str.str.upper()      # Convert to uppercase
s_str.str.contains('a')# Check for substring
s_str.str.len()        # Length of each string

---

Let me know if you want an exportable `.ipynb` notebook or want to add quiz/exercises with these!




# ğŸ“˜ Basic Functions in pandas.Series

## ğŸ“Š Structure & Type
- **`type()`**: Returns the type of the Series object.
- **`len()`**: Returns the number of elements in the Series.
- **`.shape`**: Returns a tuple indicating the number of elements.
- **`.dtype`**: Returns the data type of the Series values.
- **`.index`**: Returns the index (labels) of the Series.
- **`.values`**: Returns the underlying NumPy array of values.

---

## ğŸ” Data Inspection
- **`.head(n)`**: Returns the first `n` elements of the Series.
- **`.tail(n)`**: Returns the last `n` elements.
- **`.sample(n)`**: Returns a random sample of `n` elements.
- **`.unique()`**: Returns the unique values in the Series.
- **`.nunique()`**: Returns the number of unique elements.
- **`.value_counts()`**: Returns counts of unique values.

---

## ğŸ“ˆ Statistical Summary
- **`.sum()`**: Computes the sum of all elements.
- **`.mean()`**: Returns the average of the values.
- **`.median()`**: Returns the median value.
- **`.mode()`**: Returns the most frequent value(s).
- **`.std()`**: Returns the standard deviation.
- **`.min()`**: Returns the smallest value.
- **`.max()`**: Returns the largest value.
- **`.describe()`**: Generates summary statistics.

---

## ğŸ”¤ Sorting & Indexing
- **`.sort_values()`**: Sorts the Series by values.
- **`.sort_index()`**: Sorts the Series by index.
- **`.reindex()`**: Reorders the Series using a new index.
- **`.reset_index()`**: Resets the index, turning it into a column.

---

## ğŸ“Œ Accessing Values
- **`[]`**: Access by label or position.
- **`.loc[]`**: Access by label.
- **`.iloc[]`**: Access by integer position.

---

## ğŸ”§ Data Transformation
- **`.apply()`**: Applies a function to each element.
- **`.map()`**: Maps values using a function or dictionary.
- **`.replace()`**: Replaces values in the Series.
- **`.astype()`**: Converts Series to a specified data type.

---

## ğŸ§µ String Operations (for object/string type)
- **`.str.upper()`**: Converts strings to uppercase.
- **`.str.contains()`**: Checks if each string contains a pattern.
- **`.str.len()`**: Computes the length of each string.




Certainly! Here's a single Python markdown block you can paste into a Jupyter Notebook Markdown cell. It contains clear and organized definitions of key pandas.Series functions, without code examplesâ€”perfect for learning or teaching:


---

# ğŸ“˜ Basic Functions in pandas.Series

## ğŸ“Š Structure & Type
- **`type()`**: Returns the type of the Series object.
- **`len()`**: Returns the number of elements in the Series.
- **`.shape`**: Returns a tuple indicating the number of elements.
- **`.dtype`**: Returns the data type of the Series values.
- **`.index`**: Returns the index (labels) of the Series.
- **`.values`**: Returns the underlying NumPy array of values.

---

## ğŸ” Data Inspection
- **`.head(n)`**: Returns the first `n` elements of the Series.
- **`.tail(n)`**: Returns the last `n` elements.
- **`.sample(n)`**: Returns a random sample of `n` elements.
- **`.unique()`**: Returns the unique values in the Series.
- **`.nunique()`**: Returns the number of unique elements.
- **`.value_counts()`**: Returns counts of unique values.

---

## ğŸ“ˆ Statistical Summary
- **`.sum()`**: Computes the sum of all elements.
- **`.mean()`**: Returns the average of the values.
- **`.median()`**: Returns the median value.
- **`.mode()`**: Returns the most frequent value(s).
- **`.std()`**: Returns the standard deviation.
- **`.min()`**: Returns the smallest value.
- **`.max()`**: Returns the largest value.
- **`.describe()`**: Generates summary statistics.

---

## ğŸ”¤ Sorting & Indexing
- **`.sort_values()`**: Sorts the Series by values.
- **`.sort_index()`**: Sorts the Series by index.
- **`.reindex()`**: Reorders the Series using a new index.
- **`.reset_index()`**: Resets the index, turning it into a column.

---

## ğŸ“Œ Accessing Values
- **`[]`**: Access by label or position.
- **`.loc[]`**: Access by label.
- **`.iloc[]`**: Access by integer position.

---

## ğŸ”§ Data Transformation
- **`.apply()`**: Applies a function to each element.
- **`.map()`**: Maps values using a function or dictionary.
- **`.replace()`**: Replaces values in the Series.
- **`.astype()`**: Converts Series to a specified data type.

---

## ğŸ§µ String Operations (for object/string type)
- **`.str.upper()`**: Converts strings to uppercase.
- **`.str.contains()`**: Checks if each string contains a pattern.
- **`.str.len()`**: Computes the length of each string.


---

Let me know if you'd like a version with icons or emojis for better visual cues, or a companion code block version for hands-on practice.




Absolutely! Below is a well-organized Python markdown block for a Jupyter Notebook Markdown cell that lists top pandas data cleaning functions with concise definitions.

And after that, Iâ€™ve included a code example block for hands-on understanding. ğŸ‘


---

âœ… Python Markdown Block (Paste into a Markdown Cell)

# ğŸ§¹ Data Cleaning Functions in pandas

## ğŸ” Missing Values
- **`.isna()`**: Detects missing values (returns True for NaN).
- **`.notna()`**: Detects non-missing values (returns True where data is present).
- **`.fillna(value)`**: Fills missing values with a specified value.
- **`.dropna()`**: Drops rows (or columns) with missing values.

## ğŸ§­ Duplicates
- **`.duplicated()`**: Returns a boolean Series indicating duplicate rows.
- **`.drop_duplicates()`**: Removes duplicate rows.

## ğŸ§¼ Replacing & Mapping
- **`.replace(old, new)`**: Replaces values throughout the DataFrame.
- **`.map()`**: Maps values using a function or dictionary (on Series).
- **`.astype(type)`**: Converts data type of a column.

## ğŸ§¹ Column & Row Management
- **`.drop(labels, axis)`**: Drops specified rows or columns.
- **`.rename()`**: Renames columns or indexes.
- **`.apply(func)`**: Applies a function across DataFrame/Series.

## ğŸ•µï¸ Value Filtering & Validation
- **`.between()`**: Filters numeric values within a range.
- **`.clip(lower, upper)`**: Trims values outside of range.
- **`.where(condition)`**: Keeps values where condition is True, replaces others with NaN.


---

ğŸ§ª Code Example Block (Paste into a Code Cell)

import pandas as pd
import numpy as np

# Sample DataFrame
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Alice', 'David', None],
    'Age': [25, np.nan, 25, 30, 22],
    'Score': [88, 92, 88, np.nan, 70]
})

# Detect missing values
print(df.isna())

# Drop rows with any missing values
cleaned_df = df.dropna()

# Fill missing age with average
df['Age'] = df['Age'].fillna(df['Age'].mean())

# Check for duplicates
print(df.duplicated())

# Drop duplicate rows
df = df.drop_duplicates()

# Replace specific value
df['Name'] = df['Name'].replace('Alice', 'Alicia')

# Drop column
df = df.drop(columns='Score')

# Convert Age to integer
df['Age'] = df['Age'].astype(int)

print(df)


---

Let me know if you'd like a quiz or exercise section added to reinforce these concepts!



# ğŸ§¹ Top Data Cleaning Functions in pandas (Training Reference)

This curated list covers the most commonly used functions for data cleaning in pandas, including missing values, duplicates, type conversions, and structural cleanup. Ideal for quick reference or as a checklist during preprocessing.

---

## âœ… Top Data Cleaning Functions in pandas

---

### ğŸ” Handling Missing Values

- **`df.isna()`** â€“ Detect missing values (NaNs)
- **`df.notna()`** â€“ Detect non-missing values
- **`df.dropna()`** â€“ Drop rows/columns with missing values
- **`df.fillna(value)`** â€“ Fill missing values with a specified constant, method, or interpolation
- **`df.interpolate()`** â€“ Fill missing values using interpolation

---

### ğŸ§­ Handling Duplicates

- **`df.duplicated()`** â€“ Identify duplicated rows
- **`df.drop_duplicates()`** â€“ Remove duplicate rows

---

### ğŸ”§ Data Replacement & Transformation

- **`df.replace(old, new)`** â€“ Replace specific values
- **`df.map()`** â€“ Map values using a dictionary or function (Series only)
- **`df.apply(func)`** â€“ Apply a function across rows or columns
- **`df.applymap(func)`** â€“ Apply a function element-wise (only for DataFrame)
- **`df.astype(type)`** â€“ Convert data type of columns

---

### ğŸ§¹ Dropping & Renaming

- **`df.drop(labels, axis=0 or 1)`** â€“ Drop specified rows or columns
- **`df.rename(columns={...})`** â€“ Rename columns
- **`df.reset_index()`** â€“ Reset the index to default integer values
- **`df.set_index('column')`** â€“ Set a column as the new index

---

### ğŸ§ª Filtering & Clipping

- **`df.where(condition)`** â€“ Keep values that meet condition, replace others with NaN
- **`df.mask(condition)`** â€“ Opposite of `where()`, replaces values that meet condition
- **`df.clip(lower, upper)`** â€“ Limit values within a range
- **`df.between(a, b)`** â€“ Check if values fall within range `a` and `b`

---


Great! Letâ€™s extend your story with MultiIndexing that includes categories like Vegetables and Fruits â€” and then show how a smart shopkeeper machine (your Python code) can generate a mixed-category bill.


---

ğŸ§º 7ï¸âƒ£ MultiIndex Example with Categories: "Vegetables" and "Fruits"

import pandas as pd

# Define categories and items
categories = ["Vegetable", "Vegetable", "Vegetable", "Fruit", "Fruit", "Fruit"]
items = ["Onion", "Potato", "Brinjal", "Apple", "Banana", "Orange"]
prices = [50, 30, 45, 100, 25, 60]

# Create MultiIndex
multi_index = pd.MultiIndex.from_arrays([categories, items], names=["Category", "Item"])

# Create Series
shop_series = pd.Series(prices, index=multi_index)
print("ğŸ§¾ Price Register:\n", shop_series)


---

ğŸ§ª 8ï¸âƒ£ Creating a Mixed Bill (Veg + Fruit Purchase)

# Create a new bill: 2 Potatoes, 1 Brinjal, 3 Apples, 5 Bananas
my_bill = (
    shop_series[("Vegetable", "Potato")] * 2 +
    shop_series[("Vegetable", "Brinjal")] * 1 +
    shop_series[("Fruit", "Apple")] * 3 +
    shop_series[("Fruit", "Banana")] * 5
)

print("\nğŸ’° Total Bill for Mixed Items:", my_bill)


---

âœ… Output Sample:

ğŸ§¾ Price Register:
Category   Item   
Vegetable  Onion      50
           Potato     30
           Brinjal    45
Fruit      Apple     100
           Banana     25
           Orange     60
dtype: int64

ğŸ’° Total Bill for Mixed Items: 2*30 + 1*45 + 3*100 + 5*25 = 555


---

ğŸ’¡ Bonus Explanation for Learners:

MultiIndex is like organizing shelves in a store: first by Category, then by Item.

It helps in structuring data hierarchically.

This is useful in real-life scenarios like:

Supermarket billing systems

Financial category breakdowns

Sensor data by location and time




---

Would you like:

A .ipynb notebook with this entire storyline + explanations?

Quiz or exercises for learners to try creating their own bills?


Let me know and Iâ€™ll generate it for you!






import pandas as pd

# Define data
items_with_category = [
    ("Vegetable", "Onion"),
    ("Vegetable", "Potato"),
    ("Vegetable", "Brinjal"),
    ("Fruit", "Apple"),
    ("Fruit", "Banana"),
    ("Fruit", "Orange")
]
prices = [50, 30, 45, 100, 25, 60]

# Create MultiIndex Series
shop_series = pd.Series(prices, index=pd.MultiIndex.from_tuples(items_with_category, names=["Category", "Item"]))

# ğŸ” Accessing price of Onion under Vegetable using tuple
onion_price = shop_series[("Vegetable", "Onion")]
print("Price of Vegetable - Onion:", onion_price)



Sure! Here's the entire explanation formatted as Python Markdown (ready to use in a Jupyter Notebook):


---

## âœ… Key Properties of NumPy Arrays

1. **Homogeneous Data**: All elements must be of the same data type (e.g., int, float).
2. **Fixed Size**: Once created, the size (shape) of a NumPy array cannot be changed.
3. **Multidimensional Support**: Supports 1D, 2D, 3D or higher-dimensional arrays.
4. **Vectorized Operations**: Fast mathematical operations on whole arrays without loops.
5. **Indexing & Slicing**: Similar to Python lists but more powerful for multi-dimensional data.
6. **Memory Efficient**: Consumes less memory and is faster for numerical computations.
7. **Integrated with Pandas**: NumPy arrays are the foundation of Pandas Series and DataFrames.

---

## ğŸ“Œ Difference: NumPy Array vs. Pandas Series

| Feature               | NumPy Array                             | Pandas Series                              |
|----------------------|------------------------------------------|---------------------------------------------|
| Data Type            | Homogeneous                              | Heterogeneous allowed (but uncommon)        |
| Axis Labels          | No axis labels (only integer indices)    | Has axis labels (like dictionary keys)      |
| Built-in Index       | No                                        | Yes                                         |
| Use Case             | Math, vectorized computation              | Labeled 1D data, easier data manipulation    |
| Missing Data Support | No (use `np.nan`, but tricky)             | Yes (handles `NaN` more gracefully)         |

---

## ğŸ’¡ Example: NumPy vs Pandas Series

```python
import numpy as np
import pandas as pd

# NumPy array
np_array = np.array([10, 20, 30])

# Pandas Series (from NumPy array)
series = pd.Series(np_array, index=["a", "b", "c"])

print("NumPy Array:", np_array)
print("Pandas Series:\n", series)


---

âœ… Summary for Teaching

> "NumPy arrays are great when we want compact, fast numeric processing. But when we want labels, indexing, and data analysis, Pandas Series (or DataFrames) are more powerful. Pandas is built on top of NumPy â€” so we often convert NumPy arrays into Series or DataFrames when needed."



---

Let me know if youâ€™d like a similar block for **Lists of Dictionaries** or **Dictionaries of Lists** too!




Absolutely! Here's the full explanation formatted as Python Markdown â€“ perfect for use in a Jupyter Notebook:


---

## âœ… Difference Between Python List vs NumPy Array

| Feature                     | Python List                                | NumPy Array (`np.array`)                       |
|----------------------------|---------------------------------------------|------------------------------------------------|
| **Data Type**              | Can store mixed types (int, str, float)     | Homogeneous (all elements must be same type)   |
| **Performance**            | Slower for numerical operations             | Much faster due to internal C implementation   |
| **Memory Efficiency**      | Uses more memory                            | Compact and memory efficient                   |
| **Operations**             | No built-in vector operations               | Supports vectorized operations (e.g., `+`, `*`)|
| **Dimensionality**         | 1D only (nested lists for more)             | Supports multi-dimensional arrays (1D, 2D, ...)|
| **Functionality**          | General-purpose data container              | Optimized for mathematical & scientific computing|
| **Broadcasting**           | Not supported                               | Supported                                      |
| **Slicing & Indexing**     | Limited                                     | Advanced indexing and slicing                  |

---

## ğŸ§ª Example

```python
import numpy as np

# Python List
py_list = [1, 2, 3]
print("Python List:", py_list)

# NumPy Array
np_array = np.array([1, 2, 3])
print("NumPy Array:", np_array)

# Try addition
# print(py_list + 1)  # âŒ Error: unsupported operand
print("NumPy Array + 1:", np_array + 1)  # âœ… Vectorized addition


---

ğŸ”‘ Key Takeaway

> Use Python lists for general-purpose storage and mixed data types.
Use NumPy arrays for efficient mathematical operations and large-scale numerical data.



---

Let me know if you'd like markdowns for other comparisons like **Pandas Series vs NumPy Array** or **DataFrame vs Dictionary**!




# Basic Functions in pandas.DataFrame

---

## ğŸ—ï¸ Structure & Type

- `type(df)` : Returns the type of the DataFrame object.  
- `len(df)` : Returns the number of rows in the DataFrame.  
- `df.shape` : Returns a tuple representing (rows, columns).  
- `df.dtypes` : Returns the data types of each column.  
- `df.columns` : Returns the column labels.  
- `df.index` : Returns the row index (labels).  
- `df.values` : Returns the underlying NumPy array of values.  

---

## ğŸ” Data Inspection

- `df.head(n)` : Returns the first `n` rows of the DataFrame.  
- `df.tail(n)` : Returns the last `n` rows.  
- `df.sample(n)` : Returns a random sample of `n` rows.  
- `df.info()` : Displays index, column names, non-null counts, and dtypes.  
- `df.describe()` : Returns summary statistics for numeric columns.  
- `df.isnull()` : Detects missing (NaN) values.  
- `df.notnull()` : Detects non-missing values.  

---

## ğŸ” Data Cleaning & Transformation

- `df.drop(columns=['col1'])` : Drops specified columns.  
- `df.dropna()` : Drops rows with any NaN values.  
- `df.fillna(value)` : Fills NaN values with a specified value.  
- `df.rename(columns={'old':'new'})` : Renames columns.  
- `df.astype({'col': type})` : Changes data type of a column.  
- `df.replace(to_replace, value)` : Replaces values in the DataFrame.

---

## ğŸ“Š Statistical Summary

- `df.mean()` : Returns mean of numeric columns.  
- `df.median()` : Returns median of numeric columns.  
- `df.std()` : Returns standard deviation.  
- `df.min()` / `df.max()` : Returns min or max values.  
- `df.sum()` : Returns column-wise sum.  
- `df.corr()` : Returns correlation matrix.  
- `df.nunique()` : Returns number of unique values per column.  
- `df.value_counts()` : Used on Series (e.g., `df['col'].value_counts()`).

---

âœ… These functions form the foundation for exploring and manipulating tabular data using pandas DataFrames.




Sure! Here's a complete single Python markdown that combines everything shown in your image for filtering in pandas, structured cleanly for study or training material:

# ğŸ” Filtering in pandas

Pandas filtering involves selecting a subset of rows or columns from a DataFrame or Series based on specified conditions.  
This process is fundamental to data analysis, allowing users to isolate relevant data for further examination.

---

## âœ… Common Methods for Filtering

### 1. Boolean Indexing
This is the most common method, where a Boolean Series (`True`/`False` values) is created based on a condition applied to a column or multiple columns.  
The DataFrame is then indexed with this Boolean Series, returning only the rows where the condition evaluates to `True`.

```python
filtered_df = df[df['Age'] > 30]


---

2. Using Logical Operators

Multiple conditions can be combined using logical operators:

& â†’ AND

| â†’ OR

~ â†’ NOT


Each condition should be enclosed in parentheses to avoid operator precedence issues.

filtered_df = df[(df['Product'] == 'A') & (df['Sales'] > 100)]


---

3. isin() Method

Filters rows where values in a column are present within a specified list or array.
This mimics the SQL IN clause.

filtered_df = df[df['City'].isin(['New York', 'London'])]


---

4. String Methods (for string columns)

Used for filtering based on string patterns within a column.
Common methods include:

.str.contains()

.str.startswith()

.str.endswith()


filtered_df = df[df['Name'].str.contains('John', case=False)]


---

5. .loc[] and .iloc[]

Provide label-based and integer-location-based indexing, respectively.
Can be used in combination with filtering conditions to select specific rows and columns.

filtered_df = df.loc[df['Name'] == 'Sara', 'Score']


---

6. query() Method

Allows filtering using a string expression, improving readability for complex filters.

filtered_df = df.query("Age > 30 and Product == 'A'")


---

ğŸ“Œ Summary

These methods offer flexibility in extracting specific subsets of data from pandas DataFrames and Series,
catering to various filtering requirements in data analysis workflows.

You can copy and paste this directly into a **Jupyter notebook markdown cell** or use it in any `.md` documentation file. Let me know if youâ€™d like a companion notebook with code examples too.




Absolutely! Here's how you can structure your tutorial using your provided data. Weâ€™ll walk through:

1. Using .apply() to extract weekday from createdDate


2. Using .value_counts() to analyze request volume by weekday


3. Using .map() to modify or tag a column (e.g., adding suffix to requestStatus)


4. Difference between .apply() vs .map()


5. Using .apply() on a DataFrame row-wise




---

ğŸ§ª Sample Code Tutorial

import pandas as pd

# Sample DataFrame based on your image
data = {
    'requestNumber': [114692, 144578, 146134, 146425, 146426],
    'caseNumber': [106502, 135131, 136554, 136842, 136843],
    'requestStatus': ['QC - COMPLETE RETURN TO MAKER', 'COMPLETE', 'IN PROCESS', 'CANCELLED', 'CANCELLED'],
    'createdDate': ['2024-10-25 02:17:20.827', '2024-11-12 16:14:18.589', 
                    '2024-11-12 23:42:37.549', '2024-11-13 12:32:06.473', '2024-11-13 12:32:06.542']
}

df = pd.DataFrame(data)

# Convert createdDate to datetime
df['createdDate'] = pd.to_datetime(df['createdDate'])

# âœ… Apply function to extract weekday
df['createdWeekday'] = df['createdDate'].apply(lambda x: x.strftime('%A'))

# âœ… Count how many requestNumbers per weekday
weekday_counts = df['createdWeekday'].value_counts()

print("ğŸ“Š Request Count by Weekday:")
print(weekday_counts)


---

ğŸ§  Understanding .apply() vs .map() vs .applymap()

1. .apply() on Series (like a single column)

# Add prefix to each status using apply
df['statusLabel'] = df['requestStatus'].apply(lambda x: f"Status: {x}")

2. .map() on Series (lightweight transformation or dictionary-based)

# Tagging known statuses for demo
status_tag = {
    'COMPLETE': 'âœ… Done',
    'IN PROCESS': 'ğŸ”„ Ongoing',
    'CANCELLED': 'âŒ Cancelled'
}

# Only affects exact matches
df['statusTag'] = df['requestStatus'].map(status_tag)

3. .applymap() on entire DataFrame (only works on DataFrame, element-wise)

# Example: converting everything to string uppercase
df_upper = df[['requestStatus']].applymap(str.upper)


---

ğŸ“š Summary Table

Function	Use Case	Works On

.apply()	Row or column-wise function (flexible)	Series / DataFrame
.map()	Simple transformation or dict mapping	Series only
.applymap()	Element-wise operation	DataFrame only



---

ğŸ§  Analogy for Explanation (Optional Fun Way)

map is like a translator for each word in a sentence (each element in a column). Itâ€™s fast and direct.

apply is like a smart assistant who can take a full sentence and do anything with it.

applymap is like a filter that touches every word in every sentence, one by one.



---

ğŸ§¾ Final Display

print(df[['requestNumber', 'createdDate', 'createdWeekday', 'requestStatus', 'statusLabel', 'statusTag']])


---

ğŸ“ˆ Visual (Optional):

You could plot this for better engagement:

import matplotlib.pyplot as plt

weekday_counts.plot(kind='bar', title='Request Volume by Weekday', ylabel='Number of Requests')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()


---

Let me know if you'd like this wrapped in a Jupyter Notebook cell or turned into a Streamlit app!

